{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интеллектуальный анализ данных – весна 2022\n",
    "## Домашнее задание 4: kNN. Линейные модели. Работа с признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Правила:\n",
    "\n",
    "* Домашнее задание оценивается в 10 баллов.\n",
    "\n",
    "* Можно использовать без доказательства любые результаты, встречавшиеся на лекциях или семинарах по курсу, если получение этих результатов не является вопросом задания.\n",
    "\n",
    "* Можно использовать любые свободные источники с *обязательным* указанием ссылки на них.\n",
    "\n",
    "* Плагиат не допускается. При обнаружении случаев списывания, 0 за работу выставляется всем участникам нарушения, даже если можно установить, кто у кого списал.\n",
    "\n",
    "* Старайтесь сделать код как можно более оптимальным. В частности, будет штрафоваться использование циклов в тех случаях, когда операцию можно совершить при помощи инструментов библиотек, о которых рассказывалось в курсе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1:  Визуализация решающих поверхностей в kNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы изобразим решающую поверхность для классификатора kNN, чтобы наглядно увидеть, как классификатор принимает решения для новых объектов. Для простоты будем работать со встроенным в `sklearn` набором данных `wine`, содержащим информацию о характеристиках трёх видов вина. Описание набора можно найти [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) и [здесь](https://rdrr.io/cran/rattle.data/man/wine.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим набор данных и сохраним информацию о признаках в переменную `X`, а о зависимой переменной – в переменную `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1295.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "5    14.20        1.76  2.45               15.2      112.0           3.27   \n",
       "6    14.39        1.87  2.45               14.6       96.0           2.50   \n",
       "7    14.06        2.15  2.61               17.6      121.0           2.60   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "5        3.39                  0.34             1.97             6.75  1.05   \n",
       "6        2.52                  0.30             1.98             5.25  1.02   \n",
       "7        2.51                  0.31             1.25             5.05  1.06   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  \n",
       "5                          2.85   1450.0  \n",
       "6                          3.58   1290.0  \n",
       "7                          3.58   1295.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data = load_wine()\n",
    "X = pd.DataFrame(data['data'], columns = data['feature_names'])\n",
    "y = data['target']\n",
    "X.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 1.1 (0.5 балла)** Есть ли в наборе данных пропущенные значения? Если да, то удалите их. Есть ли в наборе данных категориальные переменные? Если да, то закодируйте их при помощи OneHot-кодирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 18.2 KB\n"
     ]
    }
   ],
   "source": [
    "X.isna().sum()# все нули значит пропусков нет! \n",
    "X.info()#все данные имеют тип float64 значит в наборе данных нет категориальных переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 1.2 (0.5 балла)** Используя функцию `train_test_split()`, разделите выборку на тренировочную и тестовую, и долю тестовой выборки задайте равной 0.3. Так как разбиение осуществляется случайным образом, не забудьте зафиксировать `np.random.seed()` для воспроизводимости результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 1.3 (1 балл)** На тренировочной выборке обучите шесть классификаторов kNN, отличающихся только числом соседей. Для первого классификатора число соседей поставьте равным 1, для второго - 3, для третьего – 5, для четвертого – 10, для пятого – 15 и для шестого – 25 (обратите внимание на параметр `n_neighbours` класса `KNeighborsClassifier`). Для обучения используйте только два признака: `alcohol` и `magnesium` – и евклидово расстояние. Не забудьте масштабировать признаки, например, при помощи модуля `StandardScaler`.\n",
    "\n",
    "Выведите долю правильных ответов на тренировочной и тестовой выборках для каждого классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "object = StandardScaler() \n",
    "S_train = pd.DataFrame(object.fit_transform(X_train[['alcohol', 'magnesium']]))\n",
    "S_test = pd.DataFrame(object.fit_transform(X_test[['alcohol', 'magnesium']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN      Train   Test\n",
      "1       0.99    0.72\n",
      "3       0.84    0.74\n",
      "5       0.81    0.74\n",
      "10      0.81    0.78\n",
      "15      0.78    0.78\n",
      "25      0.73    0.72\n"
     ]
    }
   ],
   "source": [
    "print(f\"NN {'':<4} Train{'':<2} Test\")\n",
    "for n in [1, 3, 5, 10, 15, 25]:\n",
    "    a = []\n",
    "    clf = KNeighborsClassifier(n_neighbors=n)\n",
    "    clf.fit(S_train, y_train)\n",
    "    for X_data, y_data in zip([S_train, S_test], [y_train, y_test]):\n",
    "        y_predicted = clf.predict(X_data)\n",
    "        a.append(np.around(np.mean(y_predicted==y_data), 2))\n",
    "    print(f\"{n:<7} {a[0]:<7} {a[1]:<2}\")\n",
    "#plot_decision_regions(X = np.asarray(S_train), y = y_train, clf=clf, legend=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 1.4 (0 баллов)** Установите библиотеку `mlxtend` командой ниже. Библиотеку также можно установить из терминала при помощи `pip` или `conda`, как указано [здесь](http://rasbt.github.io/mlxtend/installation/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in /home/ilya/anaconda3/lib/python3.9/site-packages (0.19.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /home/ilya/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /home/ilya/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /home/ilya/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.20.3)\n",
      "Requirement already satisfied: setuptools in /home/ilya/anaconda3/lib/python3.9/site-packages (from mlxtend) (58.0.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in /home/ilya/anaconda3/lib/python3.9/site-packages (from mlxtend) (0.24.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /home/ilya/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /home/ilya/anaconda3/lib/python3.9/site-packages (from mlxtend) (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ilya/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ilya/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ilya/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ilya/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ilya/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
      "Requirement already satisfied: six in /home/ilya/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ilya/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ilya/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.3->mlxtend) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если всё прошло успешно, то в выводе команды выше вы увидите сообщение вроде \"successfully installed\", а следующая ячейка выполнится без ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 1.5 (1 балл)** Библиотека `mlxtend` позволяет достаточно просто визуализировать решающие поверхности обученных классификаторов. Изучите [документацию](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/) библиотеки и найдите, как можно построить несколько графиков решающих поверхностей на сетке (decision regions grid). Постройте такую сетку графиков для обученных выше классификаторов.\n",
    "\n",
    "**Подсказки:**\n",
    "1. Вы можете использовать готовый код, приведённый в документации, и адаптировать его для нашего случая.\n",
    "2. Вам могут понадобиться дополнительные библиотеки, которые используются в примере из документации.\n",
    "3. Обратите внимание на то, как нужно изменить параметры `gridspec.GridSpec()` и `itertools.product()` для нашего числа классификаторов. \n",
    "4. В функции `plot_decision_region()` используйте `y_train` и нужные столбцы из `X_train`. Возможно, их придётся перевести в формат массива `numpy`.\n",
    "5. Если в задаче 1.3 вы сохраните обученные классификаторы в список, то не будет необходимости обучать их заново. \n",
    "6. Построение графика может занять некоторое время – придётся немного подождать!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import itertools\n",
    "\n",
    "gs = gridspec.GridSpec(2, 3)\n",
    "\n",
    "fig = plt.figure(figsize=(25,15))\n",
    "\n",
    "\n",
    "for i, grd in zip([1, 3, 5, 10, 15, 25],\n",
    "             itertools.product([0, 1, 2], repeat=2)):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(S_train, y_train)\n",
    "    y_predicted = clf.predict(S_test)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X = np.asarray(S_train), y = y_train, clf=clf, legend=2)\n",
    "    plt.title('n_neighbors={}'.format(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 1.6 (0.5 балла)** Прокомментируйте результаты, полученные в задачах 1.3 и 1.5. Какое число соседей оптимально использовать для обучения классификатора? Поясните ваш выбор при помощи описания геометрии данных и получаемой решающей поверхности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#По картинкам более точным приближением будет при количестве соседей равное 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2: Обученная машина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы рассмотрим упрощённую идею того, как метод ближайших соседей можно применить при моделировании движения робота. \n",
    "\n",
    "Рассмотрим робота на дискретной двумерной плоскости, который за каждый момент дискретного времени может передвинуться на одну позицию вправо, влево, вверх или вниз. На плоскости разбросаны метки одного из четырёх классов, анализируя которые робот может (но не обязан) корректировать своё перемещение. Пусть метки класса 0 соответствуют сигналу переместиться вправо, метки класса 1 – влево, класса 2 – вверх, класса 3 – вниз. \n",
    "\n",
    "Передвижение робота осуществляется по следующему правилу: с вероятностью 0.2 робот передвинется вправо, и с вероятностью 0.8 – оценит, метки какого класса преобладают среди `k` его ближайших соседей, и передвинется в направлении этого доминирующего класса. \n",
    "\n",
    "Для лучшего понимания происходящего изобразим возможное положение робота и меток:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "x = np.arange(20)\n",
    "landmarks = x + np.round(np.random.normal(2, 8, 20)) # сгенерируем случайные метки\n",
    "random_classes = np.random.randint(0, 4, 20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 7))\n",
    "scatter = ax.scatter(x, landmarks, c = random_classes)\n",
    "ax.scatter(4, 7, c = 'r', marker = 'o', label = 'robot position')\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc = \"lower left\", title = \"Classes\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.plot()\n",
    "_ = plt.legend()\n",
    "_ = plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На следующем шаге робот передвинется на 1 либо вправо, либо в направлении, которое указывают ближайшие соседи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 2.1 (1.5 балла)** Реализуйте класс, который задаёт описанное поведение робота, используя шаблон ниже:\n",
    "1. Определите атрибуты `trajectory` (переменная для хранения истории перемещения робота в виде последовательности точек с двумя координатами) и `knn` (обученный kNN классификатор, который по позиции метки предсказывает её класс).\n",
    "2. Определите метод `move()`: рассчитайте новое положение робота по правилам выше и добавьте её в историю перемещений. Подсказка: исходы можно интерпретировать как результаты подбрасывания монетки с вероятностью орла, равной 0.2. Для моделирования такого подбрасывания можно использовать, например, `np.random.binomial()` с правильными параметрами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileRobot():\n",
    "    \n",
    "    def __init__(self, k, initial_position, landmarks, classes):\n",
    "        '''\n",
    "        Attributes:\n",
    "        ------\n",
    "        k: int\n",
    "            Number of neighbours\n",
    "            \n",
    "        initial_position: ndarray\n",
    "            Initial position of the robot as a point, e.g. (-1, 1)\n",
    "            \n",
    "        landmarks: ndarray\n",
    "            numpy array of shape (n_landmarks, 2) with the euclidean positions of points\n",
    "        \n",
    "        classes: ndarray\n",
    "            numpy array of shape (n_landmarks, ) with class of landmark for each point in landmarks\n",
    "        \n",
    "        '''\n",
    "        # Store the history of movements\n",
    "        self.trajectory = \n",
    "        # kNN Classifier for determining the classes of landmarks\n",
    "        self.knn = # <ВАШ КОД ЗДЕСЬ>\n",
    "        \n",
    "        # Mapping between classes of points and movements\n",
    "        self.mapping = {0: np.array([1, 0]), \n",
    "                        1: np.array([-1, 0]),\n",
    "                        2: np.array([0, 1]),\n",
    "                        3: np.array([0, -1])}\n",
    "        \n",
    "    def move(self):\n",
    "        '''\n",
    "        Calculate new position of the robot and add it to the history\n",
    "        '''\n",
    "        \n",
    "        # <ВАШ КОД ЗДЕСЬ>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 2.2 (0.5 балла)** Дополните функцию `conduct_experiment`: определите переменную `traj` так, чтобы она содержала историю перемещения робота в виде двумерного массива numpy, в котором столбцы соответствуют координатам x и y соответствующей позиции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_experiment(x,\n",
    "                       mean = 0,\n",
    "                       std = 2, \n",
    "                       n_movements = 10, \n",
    "                       k = 3, \n",
    "                       initial_position = np.array([10, 20])):\n",
    "    \n",
    "    np.random.seed(12345)\n",
    "    # Generate random landmarks\n",
    "    landmarks = np.vstack((x, x + np.round(np.random.normal(mean, std, len(x))))).T\n",
    "    \n",
    "    # Generate random classes of landmarks\n",
    "    classes = np.random.randint(0, 4, size = len(x))\n",
    "    \n",
    "    # Conduct experiment\n",
    "    robot = MobileRobot(k, initial_position, landmarks, classes)\n",
    "    \n",
    "    for n in range(n_movements):\n",
    "        robot.move()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (10, 8))\n",
    "    scatter = ax.scatter(landmarks[:, 0], landmarks[:, 1], c = classes)\n",
    "    legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                        loc=\"lower left\", title=\"classes\")\n",
    "    ax.add_artist(legend1)\n",
    "    \n",
    "    traj = # <ВАШ КОД ЗДЕСЬ>\n",
    "    ax.plot(traj[:, 0], traj[:, 1], \n",
    "               c = 'r', marker = 'o', label = 'robot position')\n",
    "\n",
    "    plt.plot()\n",
    "    _ = plt.legend()\n",
    "    _ = plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(30)\n",
    "conduct_experiment(x, mean = 3, std = 10, k = 5, n_movements = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 2.3 (1 балл)** Как число соседей влияет на траекторию движения робота в нашем эксперименте? Постройте четыре графика с различным числом соседей на ваш выбор. А что было бы в случае, если классы назначаются меткам не случайно, а осмысленно? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3: Линейная регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы рассмотрим различные аспекты построения линейной модели. Мы будем работать с одним из классических наборов данных в статистике, содержащим информацию о бриллиантах. Описание можно посмотреть [здесь](https://www.kaggle.com/shivam2503/diamonds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/diamonds.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем решать задачу предсказания цены бриллианта `price` в зависимости от его характеристик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.1 (0.1 балла)** Есть ли в наборе данных пропущенные значения? Если да, удалите их. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum() #все нули значит пропусков нет! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.2 (0.1 балла)** Есть ли в наборе данных бессмысленные столбцы (признаки, не несущие дополнительной информации)? Если да, то удалите их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pop('Unnamed: 0')# удаляем столбец с названием Unnamed: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.3 (0.1 балла)** Линейная регрессия основана на предположении о линейной связи между признаками и целевой переменной, а потому перед выбором переменных для включения в модель имеет смысл проверить, насколько эта связь выполняется. Для следующих пунктов нам также потребуются выборочные корреляции между признаками. Выведите матрицу выборочных корреляций между всеми вещественными признаками и целевой переменной (то есть в этой матрице будет $k+1$ строка, где $k$ – количество вещественных признаков).\n",
    "\n",
    "Какие вещественные признаки коррелируют с целевой переменной больше всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "NumericData = data._get_numeric_data()\n",
    "NumericData.head()\n",
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=18)\n",
    "sns.heatmap(NumericData.corr(),\n",
    "            linewidths=0.1, vmax=1.0, \n",
    "            square=True, cmap=colormap, linecolor='white', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что лучше все коррелируются следующие величины: carat, x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.4 (0.1 балла)** Так как линейная модель складывает значения признаков с некоторыми весами, нам нужно аккуратно обработать категориальные признаки. Закодируйте категориальные переменные при помощи OneHot-кодирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dum = pd.get_dummies(data, drop_first=True)\n",
    "data_dum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.5 (0.2 балла)** Разделите выборку на тренировочную и тестовую. Долю тестовой выборки укажите равной 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = data['price']\n",
    "list_of_column = ['carat', 'x', 'y', 'z']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[list_of_column], y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.6 (0.3 балла)** Зачастую при использовании линейных моделей вещественные признаки масштабируются. При этом оценки коэффициентов теряют прямую статистическую интерпретацию (\"при увеличении $X_1$ на 1, $y$ увеличивается на $w_1$\"), но приобретают свойства, полезные в задачах машинного обучения. В этой задаче масштабируйте вещественные признаки тренировочной и тестовой выборок при помощи модуля `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "object = StandardScaler() \n",
    "S_train = pd.DataFrame(object.fit_transform(X_train))\n",
    "S_test = pd.DataFrame(object.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.7 (0.2 балла)** Оцените линейную регрессию на тренировочной выборке. Выведите среднеквадратичную ошибку на тренировочной и тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lr = LinearRegression()\n",
    "lr.fit(S_train, y_train)\n",
    "y_predicted_test = lr.predict(S_test)\n",
    "y_predicted_train = lr.predict(S_train)\n",
    "print('MSE на тестовой выборке:', mean_squared_error(y_test, y_predicted_test))\n",
    "print('MSE на тренировочной выборке:', mean_squared_error(y_train, y_predicted_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.8 (0.2 балла)** Изучите документацию модуля `LinearRegression` и выведите полученные оценки коэффициентов. Назовите вещественные переменные, оценки коэффициентов которых по модулю на порядок превышают оценки прочих вещественных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.coef_)# коэффициенты при 'carat', 'x', 'y', 'z' соответственно\n",
    "print(lr.intercept_) #свободный коэффициент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.9 (0.4 балла)** Как можно заметить из анализа корреляционной матрицы в задаче 3.3, между некоторыми признаками имеется сильная корреляция, что может быть индикатором проблемы *мультиколлинеарности*. Различия в порядке коэффициентов, выявленные в предыдущей задаче также намекают на её присутствие. Как известно, для решения этой проблемы можно либо исключить некоторые признаки из модели, либо использовать регуляризацию. Мы воспользуемся вторым вариантом. \n",
    "\n",
    "Вспомним, что смысл регуляризации заключается в том, чтобы изменить функцию потерь так, чтобы устранить проблемы, появляющиеся из-за мультиколлинеарности. При L1-регуляризации предлагается минимизировать следующую функцию потерь:\n",
    "\n",
    "$$\n",
    "\\|y - X\\hat{w}\\|^2 + \\alpha\\sum_{i=1}^k|w_i|\n",
    "$$\n",
    "\n",
    "Такая модель называется Lasso-регрессией.\n",
    "\n",
    "При L2-регуляризации предлагается минимизировать следующую функцию потерь:\n",
    "\n",
    "$$\n",
    "\\|y - X\\hat{w}\\|^2 + \\frac{1}{2}\\alpha\\|w\\|^2\n",
    "$$\n",
    "\n",
    "Такая модель называется Ridge-регрессией. \n",
    "\n",
    "Обучите Lasso-регрессию и Ridge-регрессию, уставновив гиперпараметр регуляризации равным 10. Для этого используйте модули `Lasso` и `Ridge` из `sklearn`. Сильно ли уменьшились веса? Сделайте вывод о том, насколько сильно проблема мультиколлинеарности проявлялась в изначальной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала подготовим данные для регуляризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         326\n",
       "1         326\n",
       "2         327\n",
       "3         334\n",
       "4         335\n",
       "         ... \n",
       "53935    2757\n",
       "53936    2757\n",
       "53937    2757\n",
       "53938    2757\n",
       "53939    2757\n",
       "Name: price, Length: 53940, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['price']\n",
    "data_dum.pop('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#list_of_column = ['carat', 'x', 'y', 'z']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_dum, y, test_size=0.3, random_state=42)\n",
    "object = StandardScaler() \n",
    "S_train = pd.DataFrame(object.fit_transform(X_train))\n",
    "S_test = pd.DataFrame(object.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=10)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "ridge = Ridge(10.0)\n",
    "ridge.fit(S_train,y_train)\n",
    "las = Lasso(10)\n",
    "las.fit(S_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициенты для Ridge регуляризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5299.36046069   -88.38302464   -60.57679601 -1057.321756\n",
      "    -9.14802499   -37.56886358   171.20336413   415.48016859\n",
      "   340.21593369   312.01606582   -83.21928024  -104.38686434\n",
      "  -202.29344358  -360.99775436  -441.42772206  -528.13069178\n",
      "   963.39852302  1580.72064771  1016.7986878   1644.55161501\n",
      "  1787.75171653  1267.17953038  1440.49036818]\n",
      "3951.4953122517086\n"
     ]
    }
   ],
   "source": [
    "print(ridge.coef_)# коэффициенты при 'carat', 'x', 'y', 'z' соответственно\n",
    "print(ridge.intercept_) #свободный коэффициент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициенты для Lasso регуляризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4831.59626086  -96.51685344  -71.93794363 -651.18519277   -0.\n",
      "  -28.49475941   46.13596549  206.83767582  151.39127079  139.24149436\n",
      "  -12.10568106  -37.37333901 -123.6378664  -285.767992   -368.87614678\n",
      " -469.2676605   661.82943428  875.5658754   408.43340368 1047.87685969\n",
      " 1099.90885795  848.81716871  959.29856886]\n",
      "3951.4953122517086\n"
     ]
    }
   ],
   "source": [
    "print(las.coef_)# коэффициенты при 'carat', 'x', 'y', 'z' соответственно\n",
    "print(las.intercept_) #свободный коэффициент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.10 (0.4 балла)** Как обсуждалось на семинарах, Lasso-регрессию можно использовать для отбора наиболее информативных признаков. Для следующих значений параметра регуляриазции $\\alpha$: 0.1, 1, 10, 100, 200 –  обучите Lasso- и Ridge-регрессии и постройте график измненения евклидовой нормы весов (`np.linalg.norm()` от вектора оценок коэффициентов) в зависимости от параметра $\\alpha$. Как известно, норма является численной характеристикой величины вектора, а потому по норме можно судить о том, насколько большие элементы содержит вектор оценок коэффициентов. \n",
    "\n",
    "Какой метод агрессивнее уменьшает веса? Поясните, почему Lasso-регрессию часто используют для отбора признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.1, 1, 10, 100, 200]\n",
    "norm_weight_lasso = []\n",
    "norm_weight_ridge = []\n",
    "for a in alpha:\n",
    "    ridge = Ridge(a)\n",
    "    ridge.fit(S_train,y_train)\n",
    "    las = Lasso(a)\n",
    "    las.fit(S_train, y_train)\n",
    "    norm_weight_lasso.append(np.linalg.norm(las.coef_))\n",
    "    norm_weight_ridge.append(np.linalg.norm(ridge.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4s0lEQVR4nO3deXxU5dXA8d9hD5vsCAQCKgjIkkDYRAERQSwo7lhUVCpVUai2VZC3fbG+1KWIFrVYpCoqigvyilV5VRS0ikICiGwqKEsA2RTZEcJ5/3jukEkySW5IZu4kOd/PZz4z8+TemZMh5OTe89zziKpijDHG5Kdc0AEYY4yJf5YsjDHGFMiShTHGmAJZsjDGGFMgSxbGGGMKVCHoAKKlXr162rx586DDMMaYEiU9PX2XqtbPOV5qk0Xz5s1JS0sLOgxjjClRRGRjpHE7DWWMMaZAliyMMcYUyJKFMcaYApXamoUxxuTn6NGjZGRkcPjw4aBDCUSVKlVITEykYsWKvra3ZGGMKZMyMjKoUaMGzZs3R0SCDiemVJXdu3eTkZFBixYtfO1jp6HCzZwJzZtDuXLufubMoCMyxkTJ4cOHqVu3bplLFAAiQt26dQt1VGXJImTmTI7dNBI2bgRV2LgRvfY6uO22oCMzxkRJWUwUIYX93i1ZePaPGU+FXw5mGxMUnfqUHWEYY8o8Sxaeqrs3RRwXFO6+O8bRGGPKgurVqwcdgm+WLDybaJb3F7duhbZtYexY+OwzyMyMXWDGmLhQ1kualiw8k+tO5Dh5nMOrXRsaN4ZHHoGePaFRI7jpJvjf/4UDB9w2Zf0nyZhSbOZMGJm9pMnIkdH5b/7WW2/RrVs3UlJS6NevH9u3bwdg4cKFJCcnk5ycTEpKCvv27WPbtm306tWL5ORk2rVrxyeffALAyy+/TPv27WnXrh333HNPscQlpXVZ1dTUVC1Mb6iZM2H/9bdx8/GnKEfWZ3KsUlUqPDMNhg2DPXtg3jyYOxfeeQd+/hkqV4Y2bWD1avjll6wXrFoVpnn7GWPizpo1a2jTpg0Av/sdLF+e97affw5HjuQer1wZunePvE9yMjz2WP4xVK9enf3792cb++mnn6hVqxYiwvTp01mzZg2PPPIIgwcPZuzYsfTs2ZP9+/dTpUoV/v73v3P48GHGjx9PZmYmBw8eZN++fXTv3p309HRq165N//79GT16NEOGDMn3MwgRkXRVTc25rR1ZeIYNg+rP/4NRNV9gA0kcR9hfNykrUQDUqgVDh8JLL8HOnTB/PtxyC3z1VfZEAXDwIIwbF/PvwxhT/CIlivzGiyIjI4MBAwbQvn17/va3v7Fq1SoAevbsyV133cWUKVPYs2cPFSpUoEuXLjz77LNMmDCBr776iho1arBkyRL69OlD/fr1qVChAsOGDePjjz8uemCqWipvnTt31pOxa5cqqE6aVIidRNxOkW49e6r+6U+qCxaoHj58UjEZY4rf6tWrfW+blBT5v3dSUtFiqFatWq6x3r1765tvvqmqqh999JH27t37xNdWrFihDz74oDZp0kTXrFmjqqpbtmzRadOmabt27XTGjBk6Z84cve66607sM336dL3zzjsjvn+kzwBI0wi/U+3IIod581zZ4Q9/KETpoVkexfGaNeHoUZg4Efr0cbWP/v3hwQdhyRIrlBtTQkyc6M4sh6ta1Y0Xt59//pkmTZoAMGPGjBPj69evp3379txzzz2kpqaydu1aNm7cSIMGDbj55psZMWIES5cupVu3bixcuJBdu3aRmZnJyy+/TO/evYsclyWLMKEi1vHj7rnvIlZeP0n/+Ad88QXs3u2K4Tff7GZWjRsHXbtC3bowZAg8/jisWuX+WDHGxJ1hw1wJMikJRNx9cZQkDx48SGJi4onb5MmTmTBhAldeeSXnnnsu9erVO7HtY489Rrt27ejYsSMJCQkMHDiQBQsWnCh4z549mzFjxtCoUSMeeOABzjvvPDp27EinTp245JJLivgJWIE7m+bNXYLIKSkJNmwoYOeZM2H8eNi0yR1pTJyY90/S9u3w4YfuNn8+fP+9G2/YEPr2hfPPd/c+e7YYYwovUnG3rClMgduSRZhy5SL/cS+SdbQRFd9/nz15eFPlaNEiK3H07euSiTGmWFiyKFyysK6zYZo1i3xkkVdJoti0aAEjRribKqxZ45LGhx/Ca6/B9Oluu7POykoevXu72VnGGBMDVrMIE8siVp5E3NXid9wBc+a4esfixa4o3rgxPP20q3PUrevqHuPGwfvvu6m6xhgTJVFNFiJSS0ReF5G1IrJGRHqIyAQR2SIiy73bRWHbjxORdSLytYgMCBvvLCJfeV+bIlFqFRlexAKoUiUOrqsrXx66dIF77oH33oOffoIFC+C//gsqVYJJk9wMq9q13Yyr++93LUmOHg0waGNMaRPVmoWIzAA+UdXpIlIJqAr8DtivqpNybNsWeBnoCjQGPgBaqWqmiCwGxgCfA+8AU1T13fze+2RqFuFGjIC33nLlg7juYrx/P3zySVa9Y/lydyqrenXo1SurYN6hgyvKGGMAq1lAnNQsRKQm0Au4AUBVfwF+yeeg4BJglqoeAb4XkXVAVxHZANRU1UXe6z4PDAHyTRZFlZwMzzzjZrp6U57jU/XqMHCgu4E7bbVgQVbyeOcdN163Lpx3XlbyaNkyzrOgMSaeRPNPzdOAncCzIrJMRKaLSDXva7eLyAoReUZEantjTYDNYftneGNNvMc5x3MRkZEikiYiaTt37ixS8Ckp7j6/fjFxqW5duPxyePJJWLsWNm+G55+HQYNcg5vbboMzz3RV++HDYcYMyMgo+HWNMcWufPnyJ5oADh48mD179gCwdetWrrjiioj79OnTh6KcNTlZ0UwWFYBOwFRVTQEOAGOBqcDpQDKwDXjE2z7Sn7maz3juQdVpqpqqqqn169cvUvAdOrj7ZcuK9DLBS0yE666D555z14B88w089RT06OGOOm64AZo2hVat4NZb4fXXYdeuoKM2Jv5EobN0QkICy5cvZ+XKldSpU4cnn3wSgMaNG/P6668X+fWLUzSTRQaQoapfeM9fBzqp6nZVzVTV48DTuBpFaPumYfsnAlu98cQI41FVsyaccUYJPLLIj4g7/fTb38Krr7qCzPLlMHmySxYvvghXXgn167tDq9//3iWUffuCjtyYYMWgR3mPHj3YsmULABs2bKBdu3YAHDp0iKFDh9KhQweuvvpqDh06dGKff/3rX7Rq1Yo+ffpw8803c/vttwOwc+dOLr/8crp06UKXLl349NNPixxf1GoWqvqDiGwWkTNV9WvgfGC1iDRS1W3eZpcCK73Hc4GXRGQyrsDdEljsFbj3iUh34AvgeuDxaMUdLjkZli6NxTsFpFw56NjR3e68082gSkvLqnc8+aRLJBUquGm6oWs8evRwvZmNKS1Opkf5wYNuJszTT0fex0+Pck9mZibz589nxIgRub42depUqlatyooVK1ixYgWdOnUC3Kmq+++/n6VLl1KjRg369u1Lx44dARgzZgx33nkn55xzDps2bWLAgAGsWbPGVyx5ifZFeXcAM72ZUN8BNwJTRCQZdyppA/BbAFVdJSKvAquBY8AoVQ112rsVeA5IwBW2o1rcDklJcWdlfv4ZTjklFu8YsIoVXSLo0cO1Ljl0yE3DDV0gOHGim5pbpQqcc05W8ujc2U3xNaa0ilKP8kOHDpGcnMyGDRvo3LkzF1xwQa5tPv74Y0aPHg1Ahw4d6OCdI1+8eDG9e/emTp06AFx55ZV88803AHzwwQesXr36xGvs3buXffv2UaNGjZOONarJQlWXAzmnYF2Xz/YTgVyXwKlqGtCuWIPzITnZ3a9YAeeeG+t3jwMJCS4hnH++e/7zz/Dxx1nJI7RexymnuCvKQ8njrLNsppUpWQo6AsivcdyCBSf9tqGaxc8//8ygQYN48sknTySGcJFmkeZ32cPx48dZtGgRCQkJJx1bTjbxPh+hZFHii9zF5ZRTYPBg9x9rxQr44QeYNQuuusp1zR0zBtq3h1NPhWuucW1Kvvsu6KiNKboot3c45ZRTmDJlCpMmTeJojgtqe/XqxUyvNrJy5UpWrFgBQNeuXVm4cCE//fQTx44dY/bs2Sf26d+/P0888cSJ58uLofhqySIfjRpBgwalrMhdnBo2hKuvdpe5r1vnWvM+8wxccIH7a+vmm+H0013vq9/8xq0w+MMPQUdtTOFFq0d5mJSUFDp27MisWbOyjd96663s37+fDh068PDDD9O1q5sT1KRJE+699166detGv379aNu2Lad458unTJlCWloaHTp0oG3btjz11FNFjs+6zhZgwADYscOOLgpN1V3nETpl9dFHbg1zcL2vQqes+vSxhogmEKXhCu79+/dTvXp1jh07xqWXXspNN93EpZde6nt/W4O7GKWkuDMsOZfYNgUQgTZt4Pbb4Y033LUbaWnw0EPuuo5//QsuvdRdRNilC4wd63pfWUNEY3ybMGHCiYv6WrRowZAhQ6L2XtaivADJyW5G6erVWTUMcxLKl3ezpjp3hrvvdtn3iy+yjjwmT3aJJDQjK1RY79rVjRljcpk0aVLBGxUTO7IoQIlt+xHvKlVyU8wmTHAzrH76Cd59181337/fjZ9zjuume9FFrrvusmVRXoXKlDWl9TS8H4X93u3IogBnnOEmPViyiLJq1eDCC90N4McfszdE/OMf3XidOtkbIrZqZdN0zUmpUqUKu3fvpm7duhGnppZmqsru3bupUqWK732swO3D2We7MyELFxbLy5mTsXVrVuKYP981SATXEjh83fKmTfN/HWM8R48eJSMjg8OHDwcdSiCqVKlCYmIiFXOc5rU1uIvgtttcC5g9e+yP2LigCuvXZyWPDz/Man7YsmVW8ujTx/W5Msb4ZrOhiiA5Gfbuhe+/DzoSA7iMfcYZrpHbK6+4hohffgmPPurar7/0krtQsEED9493113w9tvWENGYIrAjCx+WLHGTcmbPhssuK5aXNNF07Fj2hoiffup6+JQvn7shYiHO2RpTFthpqCI4dAhq1HCtkO6/v1he0sTSoUOwaFHWKaslSyAz0yWKnj2zN0SsYHM+TNkW82VVS5OEBGjd2mZElVgJCS4Z9O3rnu/dm70h4r33uvGaNbM3RGzXzopUxngsWfiUnGyzoUqNmjXdMrODBrnnO3a4abqh5PHWW268QQM3TTd0gWCLFpY8TJllycKnlBQ3I2rXLqhXL+hoTLFq0MAVxK+6yj3fuNH1sgpN033lFTeelJR11NG3r+s0aUwZYbOhfAq1+rBTUWVAUpJbm/yFF2DLFlizBp54wtU05syBa6+Fxo1dQ8Q77nBjP/0UdNTGRJUlC59sbYsySsQVrEaNctPhdu6E9HR4+GGXVJ55xk2Rq1fPNUS85x7XEPHAgdyvNXOmW0SnXDl3X4zrNxsTbTYbqhCaNXPtjOz/uDnhl19g8eKseseiRa7zZKghYugCwfXr3dWd4V11q1Yt9jURjCmqYpk6KyJNgNqqurI4g4uGaCSLiy92a/yELW1rTHYHDrjrOkL1jqVL3RXnIu4+p6Qkt2iUMXHipK/gFpG/icgOERkPvAfMFJFHoxFkvEtJga+/tiUXTD6qVYP+/V279bQ02L3breeR1x9lGzfC44/DZ59FPnVlTJzwMxvqUqAd8DXQCDgKrIhmUPEqOdl1yF650l0IbEyBatd2izwlJbnEkFO5cjB6dNbj1q2hU6estT+Sk90VocYEzE+y2KuqO0Rkg6oeBhCRI1GOKy6F1rZYtsyShSmkiRNdL6tINYs+fdzpqvR0d//hh/Dii24bEdeGPZRAOnVyN2+tZWNixU+yaC0iK4AzvHsBTvPz4iJSC5iOOzJR4CbcEcorQHNgA3CVqv7kbT8OGAFkAqNV9f+88c7Ac0AC8A4wRgOozCcluf+jNn3WFFqoiD1+PGza5GZLTJyYNd6kCQwenLX9Dz9kTyD/+Q+8/HLW108/PSt5hO7r1Ind92PKnAIL3CKSFGlcVSMcU+fadwbwiapOF5FKQFXgXuBHVX1QRMbiCub3iEhb4GWgK9AY+ABopaqZIrIYGAN8jksWU1T13fzeOxoFbnB/BB4+DJ9/XuwvbUz+du50iSOURNLTsxfHmzfPnUCsRbsppJPuDaWqG0WkI3CuN/SJqn7p4w1rAr2AG7zX+QX4RUQuAfp4m80AFgD3AJcAs1T1CPC9iKwDuorIBqCmqi7yXvd5YAiQb7KIlpQU+Oc/XR+68uWDiMCUWfXrw4AB7hby44/ZE8jSpe56kJCmTXMnkFNPjX3spsQrMFmIyBjgZuANb+hFEZmmqo8XsOtpwE7gWS/ZpOOODhqq6jYAVd0mIg287ZvgjhxCMryxo97jnOORYh0JjARo1qxZQd/aSUlOdk1Mv/kG2rSJylsY41+dOtCvn7uF7NnjCmvhCeTNN7NmZDVunD15dO7sxqzvlcmHn5rFCKCbqh4AEJGHgEVAQcmiAtAJuENVvxCRvwNj89k+0k+q5jOee1B1GjAN3GmoAuI7KaEi9/LllixMnKpVyzVAPO+8rLF9+9wPbej01dKl8M47bnofQMOGuRNI06aWQMwJfpKF4ArOIZlE/gWeUwaQoapfeM9fxyWL7SLSyDuqaATsCNs+fAHlRGCrN54YYTwQbdpApUru/9011wQVhTGFVKOGaz9w7rlZYwcOuBUGQ8kjPd21Ksn0/rvXq5c1+yo0lbd5c0sgZZSfZPEs8IWIzPGeDwH+VdBOqvqDiGwWkTNV9WvgfGC1dxsOPOjdv+ntMhd4SUQm4wrcLYHFXoF7n4h0B74Arqfgo5qoqVjRLXNgPaJMiVetGpx9truFHDoEK1ZkTyCTJrnVB8FdNxKeQDp1cjOzylmbudLOT4F7sogsAM7BHVHcqKp+f1XegbviuxLwHXAj7qrxV0VkBLAJuNJ7n1Ui8ioumRwDRqlq6IjmVrKmzr5LQMXtkORkt+RBqIuDMaVGQgJ06+ZuIUeOwFdfZa+B/P3vri8WuPVBciaQVq0sgZQyfqbOdgdWqeo+73kNoG3Y6aW4FK2ps+C6M4weDRkZbnq8MWXOL7/AqlXZE8iXX7p55QDVq7u/qsJrIK1b2xTCEqAoy6pOxRWqQw5EGCtTwovclixMmVSpkvuPkJICI0a4saNHYe3a7EX0p5/Oumo9ISF3AmnTxp3bNXHPV4E7/GppVT0uImV6hb0OHdz9smXwq18FG4sxcaNiRWjf3t1uuMGNZWa67pvhNZDnnnOLSQFUqeL+Q4UX0c86yyUjE1f8/NL/TkRG444mAG7D1R/KrJo14YwzrO2HMQUqX96tKNi2LVx3nRs7fhy+/TZ7AnnpJXjqKff1SpVcwgmvgbRv7xKLCYyfmkUDYArQF3d9w3zgd6q6I98dAxbNmgXAlVe6I4t166L2FsaUHcePw3ffZU8gS5dmLVdboYI74ggdfXTqBB07ulNbplgVpd3HDmBoVKIqwVJS4PXX4eefrQGoMUVWrpw7XD/jDLj6ajem6npfhSePuXPdUrbgjlratMleA0lOdlOCTbHz0+6jFe4UVENVbSciHYCLVfV/oh5dHAutyb1iRfbrnIwxxUQEWrRwt8svd2OqsHlz9gQybx7MmJG1T+vWuRNIzZqBfRulhZ+axdPAH4F/AqjqChF5CSjTySJ8bQtLFsbEiIhr796sGQwZ4sZUYdu27KewwtcEgchrgtSqFcR3UGL5SRZVVXWxZL/67FiU4ikxTj0VGjSwIrcxgRNxjRAbN468JkgogXz2GcyalfX100/PnUDq1o19/CWEn2SxS0ROx2veJyJXANuiGlUJIOKObq3thzFx6tRT4aKL3C0k55ogaWnw2mtZX09Kyl5E79zZ1gTx+EkWo3CdXFuLyBbge+DaqEZVQqSkwOTJ7mJWmxZuTAmQ15ogy5ZlP431xhtZX09MzJ48Oncuk2uC+JkN9R3QT0SqAeVCbT+MO7I4ehTWrHGz+IwxJVCdOnD++e4WsmdPVkv3UAKZOzdrTZBGjXIvKtWkSaluFudnNlRb3DUWrwF/EZG6wMRCNBMstcKL3JYsjClFatVyayj36ZM1Fr4mSCiBhK8J0qBB7jVBmjUrNQnEz2mol4BPcO3B7wf2AdOBzlGMq0Q44wyoWtWK3MaUCfmtCRK+Lvr772etCVK3bu4E0qJFiUwgfq7gXqGqHUTkG1Vt5Y0tU9WUmER4kqJ9BXfI2We7ljgLF0b9rYwxJUFoTZDwa0G++iprTZBatXIvKhVHa4IUpetsdRG5DKggIpfi1qOwK1w8yckwc6atbWGM8fhdE2TKlOxrgqSk5F4TJI5auvtJFguBwd79xd7Yx1GLqIRJToapU+H77+G004KOxhgTlypXhtRUdwv55RdYvTp7DWTq1Kw1QapVy2rpHkogrVu7PlkBKPA0VEkVq9NQS5ZA164wezZcdlnU384YU5odO+amV4YnkOXLs68J0rFj9hpI27buXPjMmTB+PGza5ArrEyfCsGGFDiGv01CWLIro0CFX97r3XvjLX6L+dsaYsia0Jkh4EX3ZMti/3329cmV39frmzVl1EXCzb6ZNK3TCsGQRRe3auQkOb70Vk7czxpR1oTVBQgnkiSdcXSSnpCTXubcQ8koW8VF+L+GSk236rDEmhsqVgzPPhGuugUmTsgrlOW3aVGxv6atSIiK/As4CTixVpap20sWTkuJOF+7aBfXqBR2NMabMadYMNm6MPF5MCjyyEJGngKuBOwABrgSSii2CUiC0toUdXRhjAjFxoqtRhKta1Y0XEz+noc5W1euBn1T1PqAH0LTYIigFQsnCOtAaYwIxbJgrZicluQu+kpJOqridHz/J4pB3f1BEGgNHgRZ+XlxENojIVyKyXETSvLEJIrLFG1suIheFbT9ORNaJyNciMiBsvLP3OutEZIpIfF3+VrcuNG1qRxbGmAANG+aK2cePu/tiTBTgr2bxbxGpBfwNWIpb12J6Id7jPFXdlWPsUVWdFD7gNSwciquNNAY+EJFWqpqJW9Z1JPA58A5wIfBuIWKIOityG2NKswKPLFT1flXdo6qzcbWK1qr6pyjEcgkwS1WPqOr3wDqgq4g0Amqq6iJ183yfB4ZE4f2LJCUF1q7NunbGGGNKEz8F7utDN1yh+xLvsR8KvCci6SIyMmz8dhFZISLPiEhtb6wJsDlsmwxvrIn3OOd4pFhHikiaiKTt3LnTZ4jFY+9ed/RXvTo0b+5mRxljTGnhp2bxHHALkAp08W65LtjIQ09V7QQMBEaJSC/cKaXTgWTc8qyPeNtGqkNoPuO5B1WnqWqqqqbWj+FSiDNnwj//GYrBzWAbOdIShjGm9PCTLM4C/gO0BtYD96nqaD8vrqpbvfsdwBygq6puV9VMVT0OPA109TbPIPssq0RgqzeeGGE8bowf79p+hDt40I0bY0xp4KdmsUZV78Z1nm0LfOTnhUWkmojUCD0G+gMrvRpEyKXASu/xXGCoiFQWkRZAS2Cxqm4D9olId28W1PXAm/6+vdjI6yLJYrx40hhjAuVnWdVWwE1ACjAP8Pv3ckNgjjfLtQLwkqrOE5EXRCQZdyppA/BbAFVdJSKvAquBY8AobyYUwK2402EJuFlQcTUTKq+LJxs3jn0sxhgTDX5WyjuOW1I1jbBagd9TUUGJZSPBmTNdjSLnTKiEBHj+ebjiipiEYYwxRVaURoI3AU/hkkV62M14Il08OXkytG8PV14Jv/mNW6rXGGNKKl8tykWkEq7ArcDXqppHi8P4Ecsji7wcPQoTJsADD0DLlvDSS26tEmOMiVcnfWThteNYD0wBngDWicjA4g+x9KlY0fXx+vBDd2TRo4frJnz8eNCRGWNM4fg5DTUZ17Kjj6r2Bs4DHo1uWKVLnz6wYgUMHgx//CMMGABb42ryrzHG5M9PstihquvCnn8H7IhSPKVWnTrw+uvw9NPw2WfQoQPMnRt0VMYY44+fZLFKRN4RkRtEZDjwFrBERC4TkcuiHF+pIuKK3enpbrrtJZfAqFG5L+gzxph44ydZVAG2A72BPsBOoA7uIr1BUYusFGvdGhYtgt//Hv7xD0hNdaepjDEmXhV4UZ6q3hiLQMqaypVdsbt/fxg+HLp2hYcfhjvucEcgxhgTT/zMhkoUkTkiskNEtovIbBFJLGg/40///u6o4oILYMwYGDQIdlhFyBgTZ/ychnoW17epMa41+FvemCkm9eu7YvcTT8D8+a74PW9e0FEZY0wWP8mivqo+q6rHvNtzQOz6f5cRIq7YnZbmksfAgXDXXXDkSNCRGWOMv2SxS0SuFZHy3u1aYHe0Ayur2rWDxYvh9tvh0UehWzdYsyboqIwxZZ3f3lBXAT/gFiu6whszUZKQAI8/Dm+9BVu2uBYh//ynW1jJGGOC4Gc9i02qerGq1lfVBqo6RFUjNOQ2xW3QIFf8PvdcuOUWuOwy2G3HdMaYAPhZz+JZIixjqqp2dBEDjRrBu+/CY4/B2LGu+P3CC9C3b9CRGWPKEj+nof4NvI27KO/tsJuJkXLlXLH7iy+gRg3o188ljl/ivvevMaa08HMaaraqzgb2hh57z02MpaS4ViE33wwPPQQ9e8K33wYdlTGmLPBzZBFi5dU4UK2aK3bPng3r17sE8txzVvw2xkSXnyu4vxKRFUBrEVkR9twE6LLLXPG7Sxe48Ua45hrYsyfoqIwxpVWBBW6sWWDcSkyEDz5wPaX+/GfXnHDmTDjnnKAjM8aUNn5qFhsj3WIRnClY+fIwbhx8+qlbma93b/jv/4Zjx4KOzBhTmhSmZmHiWNeusGwZXHcd/OUvLml8/33QURljSouoJgsR2eDVOJaLSJo3VkdE3heRb7372mHbjxORdSLytYgMCBvv7L3OOhGZImJNvCOpUcMVu196CVauhORkePnloKMyxpQGsTiyOE9Vk1U11Xs+Fpivqi2B+d5zRKQtMBQ4C7gQ+IeIlPf2mQqMBFp6twtjEHeJdc018OWXrs/Ur3/t1svYty/oqIwxJZmf2VDdRWSJiOwXkV9EJFNE9hbhPS8BZniPZwBDwsZnqeoRVf0eWAd0FZFGQE1VXaSqCjwfto/JQ/PmsHChq1+8+KI7yvjii6CjMsaUVH6OLJ4ArgG+BRKA3wCP+3x9Bd4TkXQRGemNNVTVbQDefQNvvAmwOWzfDG+sifc453guIjJSRNJEJG3nzp0+Qyy9KlSACRNc0sjMdBfx/fWv7rExxhSGr9NQqroOKK+qmar6LHCez9fvqaqdgIHAKBHplc+2keoQms94pDinqWqqqqbWr29LboSccw4sXw5XXAHjx8P558PmzQXuZowxJ/hJFgdFpBKwXEQeFpE7gWp+XlxVt3r3O4A5QFdgu3dqCe8+tIhoBtA0bPdEYKs3nhhh3BRCrVqu2P3cc26BpY4d3VXgxhjjh59kcZ233e3AAdwv9MsL2klEqolIjdBjoD+wErdE63Bvs+HAm97jucBQEaksIi1whezF3qmqfV7tRIDrw/YxhSDiit3Ll8Ppp7sjjZtvhgMHgo7MGBPvCryCO+wCvMMi8gBQWVX9zK1pCMzxZrlWAF5S1XkisgR4VURGAJuAK733WSUirwKrgWPAKFUNnV2/FXgOVzN517uZk3TGGe4ivv/+b9eQ8OOP3VFHp05BR2aMiVeiBXSg8047DQOmAH8BqgCPqOrfoh/eyUtNTdW0tLSgw4h7H33kLuTbsQMeeADuvNO1RDfGlE0ikh52qcMJfn4tjAJuwc2K6gScBtxYvOGZoJx3nrsmY9Ag+MMf4MILYdu2oKMyxsQbP8lir6qmAetV9UdVPQgcjnJcJobq1nXF7n/+E/7zH7ca31tvBR2VMSae+EkWp4nIXKCFiMwVkbeAFlGOy8SYCIwc6RZXSkyEiy+G22+HQ4eCjswYEw/8tCi/xLt/JGxsUhRiMXGgTRv4/HO4916YPBkWLHDF7/btg47MGBMkPy3KFwJrgRrebY03ZkqpypXhkUdg3jzYtcstsPTEE7YanzFlmZ/eUFcBi3FTXK8CvhCRK6IdmAnegAFuNb5+/eCOO2DwYDdryhhT9vipWYwHuqjqcFW9HncV9p+iG5aJFw0auGL344+7Vfk6dID/+7+gozLGxJqfZFHOa9cRstvnfqaUEHHF7iVLoF49N73297+HI0eCjswYEyt+funPE5H/E5EbROQG4G3sCuoyqX17lzBGjXLF7+7dYe3aoKMyxsSCnwL3H4FpQAegIzBNVe+OdmAmPiUkuGL33LmQkeFahEybZsVvY0o7vy3KZ6vqXap6p6rOEZFBInK9iCRFO0ATnwYPdsXvc86B3/4WLr8cdu8OOipjTLQUeJ2Fd0FetiHgHFy/KDtrXYY1auSm1z76KIwb59qev/CCayFijCld/BxZtMFdkBd+26Wq76jqD9EMzsS/cuVcsfvzz6FaNbew0r33wtGjQUdmjClOfpLFPlVdGHZbAPhpUW7KkE6dYOlSGDHCda/t2RPWrQs6KmNMcfGTLM4SkXUislhE3hCRm3Btyo3Jplo1ePppeP11lyhSUmDGDCt+G1Ma+EkWjYGzgaHAk7iL8s4UkV4iUi+awZmS6fLLXdvzzp3hhhvg17+GPXuCjsoYUxR+ps7uVtUdqvqdqs5X1VuAO4DzgAZRj9CUSE2bwvz5MHEivPYaJCe79ufGmJLJT2+oOjlvwCxVvU9VV8cgRlNClS/vit2ffuoe9+4NEybAsWNBR2aMKSw/p6F2AauANCDdu9l6pca3bt1g2TK49lq47z6XNDZsCDoqY0xh+EkWI4EM3JTZlqraQlVPi25YprSpWdMVu2fOhJUr3TUZs2YFHZUxxi8/NYvpuIvwKgOficiwqEdlSq1f/xqWL4ezzoJrroHhw2GfTcQ2Ju75qVlcBvwK2ABMBe4RkS+jHJcpxVq0gI8/hj//GV580U2xXbw46KiMMfnxcxpqcNitF65msTSaQZnSr0IFV79YuNBd7d2zp7uYLzMz6MiMMZH4OQ11Y6Sb3zcQkfIiskxE/u09nyAiW0RkuXe7KGzbcd4FgF+LyICw8c4i8pX3tSkiIoX9Rk18Ouccd03GZZe5mVP9+rlutsaY+HIyjQQBUNWLfb7HGGANUDNs7FFVnZTjfdriLvw7C3ch4Aci0kpVM3Gnv0YCnwPvABdia2qUGrVquWL3wIFukaUOHWD6dJdAjDHx4WQbCT7i58VFJBFX75juY/NLcNdvHFHV74F1QFcRaQTUVNVFqqrA88AQP+9vSg4Rd7X3smVw+unuKvCRI+HAgaAjM8bAyTUSXKiqC32+/mPA3cDxHOO3i8gKEXlGRGp7Y02AzWHbZHhjTbzHOcdzEZGRIpImImk7d+70GaKJJy1buov4xo51RxedO7sEYowJlp9k0VFE9ojIDyKyVEQe99MTSkQGATtUNT3Hl6YCpwPJwDayjlIi1SE0n/Hcg6rTVDVVVVPr169fUIgmTlWq5IrdH3zgptV26+aWcT2e808OY0zM+Clwlwfq4H7BXw38AMzw8do9gYtFZAMwC+grIi+q6nZVzVTV48DTuMaE4I4Ymobtnwhs9cYTI4ybUq5vX7ca369+5dbMGDgQtm0LOipjyia/y6oeV9UDqvqtqk4E5vnYZ5yqJqpqc1zh+kNVvdarQYRcCqz0Hs8FhopIZRFpAbQEFqvqNmCfiHT3ZkFdD7zp+zs0JVrduvDGG/DUU/DJJ674/e9/Bx2VMWWPn4vy2ud4Xpk8agY+PexNg12B61x7J4CqrgJeBVbjktEobyYUwK24Ivk6YD02E6pMEXHrfKenQ5Mmbv3vO+6AQ4eCjsyYskO0gJVpRGQZMEZVPxaR84ApwExVfTAWAZ6s1NRUTUuzfoelzZEjbr3vRx+Fdu3g5ZfdvTGmeIhIuqqm5hz3cxpqIPCQiMwB/gu4LN4ThSm9Kld2xe5334UdOyA1FZ54wlbjMyba/BS4fwD6AzWAN1X126hHZUwBLrzQFb/79nWnpC6+GGy2tDHR46dmsQ/YAvQAHhORfSKyN+qRGVOAhg3h7bfh73+H995zxe/33gs6KmNKJz9HFjVUtaaqVlPVcqHnsQjOmIKIwOjRsGQJ1KkDAwbAH/7gahvGmOLj58giQUTaeY+HisjtImLJwsSVDh0gLQ1uuw0eeQR69IC1a4OOypjSw0+B+3+BF0VkHnARrlfUa9EMypiTkZAATz4Jb74Jmza5ViHTp1vx25ji4CdZNAU6Ae1V9XpVHQWcGt2wjDl5F1/sit89esDNN8MVV8CPPwYdlTElm59kcRSoBewWkdoiUie6IRlTdI0bu2L3ww/DW2+501QLFgQdlTEll59kcQqQhps6uxS3Up7VLEzcK1cO/vhHWLQIqlZ102zHj3cr8xljCsfPbKjmqnqaqrYIv8UiOGOKQ+fOsHQp3HQT/PWvbnW+deuCjsqYkiXPZCEid4c9vjLH1/4azaCMKW7Vq7ti96uvwjffQEoKPP+8Fb+N8Su/I4uhYY/H5fjahVGIxZiou/JKt+Z3p04wfDgMGwY//xx0VMbEv/ySheTxONJzY0qMZs3gww/hf/7HHWl07AiffRZ0VMbEt/yShebxONJzY0qU8uVdsfs//3GF8HPPhfvug2PHgo7MmPiUX7LoKCJ7vd5QHbzHoeft89nPmBKje3dYvhx+/WuYMAH69IGNGwMOypg4lGeyUNXyXk+oGqpawXscel4xlkEaE001a8ILL8CLL7qL+Tp2hFmzgo7KmPjia1lVY8qCYcPcUUabNnDNNXDjjbBvX9BRGRMfLFkYE+a00+Djj+FPf3JTa1NSYPHioKMyJniWLIzJoWJF+Mtf4KOP4JdfoGdPePBByMwseF9jSitLFsbkoVcvd03GpZe6db8vuAAyMoKOyphgWLIwJh+1a8Mrr8Azz7jTUR07wpw5QUdlTOxZsjCmACKu2L10KbRoAZddBr/9LRw4EHRkxsRO1JOFiJQXkWUi8m/veR0ReV9EvvXua4dtO05E1onI1yIyIGy8s4h85X1tiojYFeQm5lq1cld63303TJsGqalu9pQxZUEsjizGAGvCno8F5qtqS2C+9xwRaYvrR3UWrvfUP0SkvLfPVGAk0NK7WW8qE4hKleChh+D9911PqW7d4NFH4fjxoCMzJrqimixEJBH4FTA9bPgSYIb3eAYwJGx8lqoeUdXvgXVAVxFpBNRU1UWqqsDzYfsYE4h+/dwFfAMHwl13wUUXwQ8/BB2VMdET7SOLx4C7gfC/uxqq6jYA776BN94E2By2XYY31sR7nHM8FxEZKSJpIpK2c+fOYvkGjMlLvXqu2D11Kixc6Fbje/vtoKMyJjqilixEZBCwQ1XT/e4SYUzzGc89qDpNVVNVNbV+/fo+39aYkycCt9wC6enQqBEMGgSjR8Phw0FHZkzxiuaRRU/gYhHZAMwC+orIi8B279QS3v0Ob/sMoGnY/onAVm88McK4MXGjbVv44gv43e/g8ceha1dYuTLoqIwpPlFLFqo6TlUTVbU5rnD9oapeC8wFhnubDQfe9B7PBYaKSGURaYErZC/2TlXtE5Hu3iyo68P2MSZuVKniit3vvAPbt0OXLvCPf9hqfKZ0COI6iweBC0TkW+AC7zmqugp4FVgNzANGqWqowcKtuCL5OmA98G6sgzbGr4EDXfG7Tx8YNQouuQSshGZKOtFS+mdPamqqpqWlBR2GKcOOH3enpO6+G+rUccu4zpoFmza51fomTnSdbo2JJyKSrqqpOcftCm5joqRcORgzxrUJKVfOXZ+xcaM7LbVxI4wcCTNnBh2lMf5UCDoAY0q7jh3dMq45HTzoZlJt3gxJSe5oIynJzaqKtL0xQbJkYUwM5NWtdv9+19E2XIUKkJiYPYGE3zdrBlWrRj9mY8JZsjAmBpo1i7y2d1KSm2K7aZO7bdyY/X7hQtiyJfdaGvXqRU4mocf16rlrQIwpLpYsjImBiRNdjeLgwayxqlXdePXq7jqNtm0j73vsGGzdmjuRbNwIX38N772XuwNuQkLko5LQfWKiW+TJGL8sWRgTA6FZT+PHF342VIUKWaefIlGFn37KnkTCH3/5pbvuI5wING4c+agkdF+zZtG+Z1O62NRZY8qAw4ddIT3S0UnoFNjRo9n3qVUr/6OTU091s7xM6ZLX1Fk7sjCmDKhSBVq2dLdIjh93Rx95HZ188gns2ZN9n4oVoWnTyEclSUnua1WqRP1bMzFiycIYQ7lybspuo0bQvXvkbfbujXxUsnEjfPCBK8TnPFHRsGH+Ryd16lghvqSwZGGM8aVmTWjXzt0iOXrUTRGOlFC++sq1bz90KPs+1arlnUiSklxdpYL9looL9s9gjCkWFSu6NcpbtIj8dVXYtSvvo5O0NPf1cOXLQ5MmeU8RbtbMzSYz0WfJwhgTEyJQv767de4ceZuDB/O+5uTTT+GVV9xU4nB16uR/dNKggZ3qKg6WLIwxcaNqVWjd2t0iycyEbdsiF+HXr4cPP4R9+7LvU7ly1lFIpKOTpk3d2uomf5YsjDElRvny7oLCxEQ4++zcX1eFn3/Oe4rwu++6ZBNOxE0Dzu/opFatmHx7cc2ShTGm1BBxv9hr1XINHCM5csQV4iMllGXL4M033TbhatbMf1ZXWWj+aMnCGFOmVK4Mp5/ubpEcP+4Wq4qUTDZuhEWL4Mcfs+9TFpo/WrIwxpgw5cq560MaNnRrqUeyf3/es7oWLnRHLsePZ9+nfv38j07ivfmjJQtjjCmkwjR/zJlQ1qyBefOyN5WEyM0fwx83aZJ/88eZM0+u95hfliyMMaaYhTd/PPfc3F9Xdaey8jo6idT8sVw5d5FipKOSlSvhvvuyLnoMrcQIxZcwrJGgMcbEoUOHsgrxkRLK5s25mz/mlJQEGzYU7n2tkaAxxpQgCQkFN3/84QeXPM4+O3dfLnBfKy7WYNgYY0qg0Gmp7t3zXuskr/GTer/ieyljjDFBmDgx99Tc0EqMxSVqyUJEqojIYhH5UkRWich93vgEEdkiIsu920Vh+4wTkXUi8rWIDAgb7ywiX3lfmyISzxPMjDEmtoYNg2nTXI1CxN1Pm1ZyZkMdAfqq6n4RqQj8R0Te9b72qKpOCt9YRNoCQ4GzgMbAByLSSlUzganASOBz4B3gQuBdjDHGAC4xFGdyyClqRxbq7PeeVvRu+U29ugSYpapHVPV7YB3QVUQaATVVdZG6qVvPA0OiFbcxxpjcolqzEJHyIrIc2AG8r6pfeF+6XURWiMgzIlLbG2sCbA7bPcMba+I9zjke6f1GikiaiKTt3LmzOL8VY4wp06KaLFQ1U1WTgUTcUUI73Cml04FkYBvwiLd5pDqE5jMe6f2mqWqqqqbWr1+/iNEbY4wJiclsKFXdAywALlTV7V4SOQ48DYS6r2QATcN2SwS2euOJEcaNMcbESDRnQ9UXkVre4wSgH7DWq0GEXAqs9B7PBYaKSGURaQG0BBar6jZgn4h092ZBXQ+8Ga24jTHG5BbN2VCNgBkiUh6XlF5V1X+LyAsikow7lbQB+C2Aqq4SkVeB1cAxYJQ3EwrgVuA5IAE3C6rAmVDp6em7RGTjScZeD9hV4FaxZ3EVjsVVOBZX4ZTWuJIiDZba3lBFISJpkXqjBM3iKhyLq3AsrsIpa3HZFdzGGGMKZMnCGGNMgSxZRDYt6ADyYHEVjsVVOBZX4ZSpuKxmYYwxpkB2ZGGMMaZAliyMMcYUyJJFGBG50GuPvk5ExgYYR1MR+UhE1njt3cd443m2d49hbBu8dvHLRSTNG6sjIu+LyLfefe2CXqeYYzoz7DNZLiJ7ReR3QX1eXs+zHSKyMmwsz88or9b8MYrrbyKy1uvVNifsQtrmInIo7LN7KsZxFXopgxjF9UpYTBu83ncx+7zy+d0Q/Z8vVbWbq9uUB9YDpwGVgC+BtgHF0gjo5D2uAXwDtAUmAH8I+HPaANTLMfYwMNZ7PBZ4KOB/xx9wFxYF8nkBvYBOwMqCPiPv3/VLoDLQwvsZLB/DuPoDFbzHD4XF1Tx8uwA+r4j/dkF/Xjm+/gjw51h+Xvn8boj6z5cdWWTpCqxT1e9U9RdgFq5tesyp6jZVXeo93gesIY9Ou3HiEmCG93gGwbaQPx9Yr6one/V+kanqx8CPOYbz+owituaPVVyq+p6qHvOefk72PmwxkcfnlZdAP68Qr/XQVcDL0XjvfGLK63dD1H++LFlkyatFeqBEpDmQAuTX3j2WFHhPRNJFZKQ31lBdDy+8+wYBxBUylOz/gYP+vELy+ozi6efuJrK30mkhIstEZKGInBtAPIVZyiDWzgW2q+q3YWMx/bxy/G6I+s+XJYssvluhx4qIVAdmA79T1b3k3d49lnqqaidgIDBKRHoFEENEIlIJuBh4zRuKh8+rIHHxcyci43E92WZ6Q9uAZqqaAtwFvCQiNWMYUmGXMoi1a8j+R0lMP68Ivxvy3DTC2El9XpYssuTVIj0Q4painQ3MVNU3ADTv9u4xo6pbvfsdwBwvhu3idRP27nfEOi7PQGCpqm73Ygz88wqT12cU+M+diAwHBgHD1DvR7Z222O09Tsed624Vq5jy+beLh8+rAnAZ8EpoLJafV6TfDcTg58uSRZYlQEsRaeH9hToU1zY95rzzof8C1qjq5LDxvNq7xyquaiJSI/QYVxxdifuchnubDSe4FvLZ/toL+vPKIa/PKGJr/lgFJSIXAvcAF6vqwbDx+uI6RiMip3lxfRfDuAq1lEGs4vL0A9aq6okVPGP1eeX1u4FY/HxFu3pfkm7ARbjZBeuB8QHGcQ7uUHEFsNy7XQS8AHzljc8FGsU4rtNwMyu+BFaFPiOgLjAf+Na7rxPAZ1YV2A2cEjYWyOeFS1jbgKO4v+xG5PcZAeO9n7mvgYExjmsd7px26OfsKW/by71/4y+BpcDgGMeV579dkJ+XN/4ccEuObWPyeeXzuyHqP1/W7sMYY0yB7DSUMcaYAlmyMMYYUyBLFsYYYwpkycIYY0yBLFkYY4wpkCULY6LA60har6jbGBMvLFkYY4wpkCULY4pIRP7Xa6y4Kqy5Yuhrzb31ImZ4TfFeF5GqYZvcISJLxa0R0trbp6uIfOY1pftMRM6M6TdkTASWLIwpuptUtTOQCowWkbo5vn4mME1VOwB7gdvCvrZLXWPGqcAfvLG1QC91Ten+DPw1qtEb44MlC2OKbrSIfIlbD6Iprv9OuM2q+qn3+EVcy4aQUCO4dNwCOgCnAK95K7Q9CpwVjaCNKQxLFsYUgYj0wTWW66GqHYFlQJUcm+XsqRP+/Ih3nwlU8B7fD3ykqu2AwRFez5iYs2RhTNGcAvykqge9mkP3CNs0E5Ee3uNrgP/4eM0t3uMbiiVKY4rIkoUxRTMPqCAiK3BHBJ9H2GYNMNzbpg6uPpGfh4EHRORT3JrixgTOus4aE0Xe0pf/9k4pGVNi2ZGFMcaYAtmRhTHGmALZkYUxxpgCWbIwxhhTIEsWxhhjCmTJwhhjTIEsWRhjjCnQ/wPU2xhjWrCaAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ylabel('Евклидова норма весов')\n",
    "plt.xlabel('alpha')\n",
    "plt.plot(alpha, norm_weight_lasso,'o-', color='blue', label='Lasso')\n",
    "plt.plot(alpha, norm_weight_ridge,'o-', color='red', label='Ridge')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика видим что ругуляризация Lasso агрессивнее уменьшает веса, именно поэтому ее и используют для отбора признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.11 (0.5 балла)** \n",
    "В зависимости от значения параметра $\\alpha$ в Lasso-регрессии зануляются разные оценки коэффициентов. Оптимальное значение $\\alpha$ можно подобрать, например, при помощи кросс-валидации по тренировочной выборке. \n",
    "\n",
    "Для проведения кросс-валидации можно использовать модуль `LassoCV`. Этот модуль принимает список значений $\\alpha$ (параметр `alphas`) и при обучении проводит кросс-валидацию для каждого значения из этого списка, сохраняя MSE на каждом участке кросс-валидации (количество участков – параметр `cv`) в матрицу ошибок (то есть итоговая матрица будет иметь размер `len(alphas)` $\\times$ `cv`). После обучения модели матрицу ошибок можно получить, обратившись к атрибуту `.mse_path_`. \n",
    "\n",
    "Заметим, что модель может использовать $\\alpha$ не в том порядке, в котором вы подаёте их в функцию: для определения порядка используйте атрибут `.alphas_` Установите количество участков для кросс-валидации (параметр `cv`) равным 5.\n",
    "\n",
    "Усредните ошибки для каждого значения $\\alpha$ (то есть по строкам матрицы ошибок) и выберите то значение, которое даёт наибольшее качество. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16051572.96247433 16051572.96247433  5435006.79248516  2085551.34725515\n",
      "  1466768.09289901]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lascv = LassoCV(cv = 5, alphas=[0.1, 1, 10, 100, 200], normalize=True, tol=1e-2)\n",
    "lascv.fit(S_train, y_train)\n",
    "lascv.alphas_\n",
    "matr = lascv.mse_path_\n",
    "print(matr.mean(axis=1))\n",
    "alpha[np.argmin(matr.mean(axis=1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается что наибольшее качество дает $\\alpha$ = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.12 (0.5 балла)** Обучите итоговую Lasso-регрессию с выбранным параметром $\\alpha$ на тренировочной выборке. Выведите полученные коэффициенты и прокомментируйте, какие признаки оказались неинформативными, а какие – наиболее информативными. Приведите возможное смысловое объяснение этого результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3585.47144858   -0.           -0.            0.            0.\n",
      "    0.           -0.            0.           -0.           -0.\n",
      "    0.            0.            0.           -0.           -0.\n",
      " -120.28435024    0.          -39.44329564 -245.03616924    0.\n",
      "    0.            0.           28.07269624]\n",
      "3951.495312251708\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>...</th>\n",
       "      <th>color_H</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19497</th>\n",
       "      <td>1.21</td>\n",
       "      <td>61.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.92</td>\n",
       "      <td>6.87</td>\n",
       "      <td>4.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  depth  table     x     y     z  cut_Good  cut_Ideal  \\\n",
       "19497   1.21   61.3   57.0  6.92  6.87  4.23         0          1   \n",
       "\n",
       "       cut_Premium  cut_Very Good  ...  color_H  color_I  color_J  clarity_IF  \\\n",
       "19497            0              0  ...        1        0        0           0   \n",
       "\n",
       "       clarity_SI1  clarity_SI2  clarity_VS1  clarity_VS2  clarity_VVS1  \\\n",
       "19497            0            0            0            0             0   \n",
       "\n",
       "       clarity_VVS2  \n",
       "19497             1  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las = Lasso(200)\n",
    "las.fit(S_train, y_train)\n",
    "print(las.coef_)# коэффициенты\n",
    "print(las.intercept_) #свободный коэффициент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3.13 (0.4 балла)** Сделайте предсказания обученной Lasso-регрессии на тестовой выборке и сравните среднеквадратичную ошибку с ошибкой обычной линейной регрессии из задачи 3.7. Какую модель лучше использовать для предсказаний? Приведите возможное объяснение, почему одна модель оказалась лучше другой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
